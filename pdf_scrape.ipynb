{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE with CAUTION!!!\n",
    "## 2016 ~ 2019 ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import camelot\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to remove items from the original main list\n",
    "def remove_item(target, original):\n",
    "    for item in target:\n",
    "        original.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q1-2016.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q1-2017.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q1-2018.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q1-2019.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q2-2016.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q2-2017.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q2-2018.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q2-2019.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q3-2016.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q3-2017.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q3-2018.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q3-2019.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q4-2016.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q4-2017.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q4-2018.pdf',\n",
       " 'C:\\\\Users\\\\johnn\\\\OneDrive\\\\Desktop\\\\UofT SCS Data Analytics Boot Camp\\\\Module 20 - Final Project\\\\Data-Analytics-Boot-Camp---Final-Project\\\\pdf_collection\\\\condo_report_Q4-2019.pdf']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go to the raw directory which saves all the pdf files\n",
    "file_path = r'C:\\Users\\johnn\\OneDrive\\Desktop\\UofT SCS Data Analytics Boot Camp\\Module 20 - Final Project\\Data-Analytics-Boot-Camp---Final-Project\\pdf_collection'\n",
    "all_pdf_files = glob.glob(file_path + \"/*.pdf\")\n",
    "all_pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the table data\n",
    "pdf_table_1 = []\n",
    "pdf_table_2 = []\n",
    "for pdf_file in all_pdf_files:\n",
    "    table_collection = camelot.read_pdf(pdf_file, pages = \"all\")\n",
    "    pdf_table_1.append(table_collection[3].df.loc[0][0])\n",
    "    pdf_table_2.append(table_collection[4].df.loc[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the first table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_1_process(info_raw_1):\n",
    "    # Split the contents by delimiers\n",
    "    info_split_1 = info_raw_1.split(\"\\n\")\n",
    "\n",
    "    # Remove dummy contents\n",
    "    info_split_clean_1 = info_split_1[8:]\n",
    "\n",
    "    # Extract column names and then remove from the main list\n",
    "    column_names_1 = info_split_clean_1[:8]\n",
    "    remove_item(column_names_1, info_split_clean_1)\n",
    "\n",
    "    # Hardcode to remove this weird \"Gwillimbury\" from the list :(\n",
    "    info_split_clean_1.remove(\"Gwillimbury\")\n",
    "\n",
    "    # Hardcode the number of regions in Ontario then get the notations, then remove from the main list\n",
    "    num_region_Ontario = 41\n",
    "    Toronto_notation_1 = []\n",
    "    for i in range(num_region_Ontario):\n",
    "        Toronto_notation_1.append(info_split_clean_1[i * 9])\n",
    "    remove_item(Toronto_notation_1, info_split_clean_1)\n",
    "\n",
    "    # Determine the number of rows for the table\n",
    "    num_row_1 = len(Toronto_notation_1)\n",
    "\n",
    "    # Fill in column values\n",
    "    column_values_1 = []\n",
    "    for i in range(num_row_1):\n",
    "        column_values_1.append(info_split_clean_1[i * 8:(i+1)*8])\n",
    "\n",
    "    # Form dataframe and assign index\n",
    "    final_df_1 = pd.DataFrame(column_values_1, columns = column_names_1)\n",
    "    final_df_1.index = Toronto_notation_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all the processed table_1\n",
    "file_index = 2016\n",
    "quarter = 1\n",
    "for table_1 in pdf_table_1:\n",
    "    if file_index > 2019:\n",
    "        quarter = quarter + 1\n",
    "        file_index = 2016\n",
    "        table_1_process(table_1)\n",
    "        final_df_1.to_csv(f'table_processed/{file_index}_Q{quarter}_table_1.csv', index = True, encoding = 'utf-8')\n",
    "        file_index = file_index + 1\n",
    "    else:\n",
    "        table_1_process(table_1)\n",
    "        final_df_1.to_csv(f'table_processed/{file_index}_Q{quarter}_table_1.csv', index = True, encoding = 'utf-8')\n",
    "        file_index = file_index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the second table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_2_process(info_raw_2):\n",
    "    # Split the contents by delimiers\n",
    "    info_split_2 = info_raw_2.split(\"\\n\")\n",
    "\n",
    "    # Remove dummy contents\n",
    "    info_split_clean_2 = info_split_2[8:]\n",
    "\n",
    "    # Extract column names and then remove from the main list\n",
    "    column_names_2 = info_split_clean_2[:8]\n",
    "    remove_item(column_names_2, info_split_clean_2)\n",
    "\n",
    "    # Extract notations and combine, then remove from the main list\n",
    "    Toronto_area = list(filter(lambda x: 'Toronto' in x, info_split_clean_2))\n",
    "    other_notation = list(filter(lambda x: 'TREB' in x, info_split_clean_2))\n",
    "    Toronto_notation = other_notation + Toronto_area\n",
    "    remove_item(Toronto_notation, info_split_clean_2)\n",
    "\n",
    "    # Determine the number of rows for the table\n",
    "    num_row_2 = len(Toronto_notation)\n",
    "\n",
    "    # Fill in column values\n",
    "    column_values_2 = []\n",
    "    for i in range(num_row_2):\n",
    "        column_values_2.append(info_split_clean_2[i * 8:(i+1)*8])\n",
    "\n",
    "    # Form dataframe and assign index\n",
    "    final_df_2 = pd.DataFrame(column_values_2, columns = column_names_2)\n",
    "    final_df_2.index = Toronto_notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all the processed table_2\n",
    "file_index = 2016\n",
    "quarter = 1\n",
    "for table_2 in pdf_table_2:\n",
    "    if file_index > 2019:\n",
    "        quarter = quarter + 1\n",
    "        file_index = 2016\n",
    "        table_2_process(table_2)\n",
    "        final_df_2.to_csv(f'table_processed/{file_index}_Q{quarter}_table_2.csv', index = True, encoding = 'utf-8')\n",
    "        file_index = file_index + 1\n",
    "    else:\n",
    "        table_2_process(table_2)\n",
    "        final_df_2.to_csv(f'table_processed/{file_index}_Q{quarter}_table_2.csv', index = True, encoding = 'utf-8')\n",
    "        file_index = file_index + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
